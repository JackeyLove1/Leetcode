import numpy as np
import re
from collections import Counter
from typing import List
import math

# è¶…å‚æ•°
laplace = 0.1

# è¿‡æ»¤è¯
stopwords = "about all along also although among and any anyone anything are around because " \
            "been before being both but came come coming could did each else every for from get getting going got gotten had has have having her here hers him his how " \
            "however into its like may most next now only our out particular same she " \
            "should some take taken taking than that the then there these they this those " \
            "throughout too took very was went what when which while who why will with " \
            "without would yes yet you your" \
            "com doc edu encyclopedia fact facts free home htm html http information " \
            "internet net new news official page pages resource resources pdf site " \
            "sites usa web wikipedia www " \
            "one ones two three four five six seven eight nine ten tens eleven twelve " \
            "dozen dozens thirteen fourteen fifteen sixteen seventeen eighteen nineteen " \
            "twenty thirty forty fifty sixty seventy eighty ninety hundred hundreds " \
            "thousand thousands million millions "


# --------------------------------Step0-------------------------------

# ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å°†è‹±æ–‡å•è¯åˆ‡å‰²
def textParse(strings):
    # æ›¿æ¢æ ‡ç‚¹ç¬¦å·
    # strings.replace("'", " ")
    # strings.replace(",", " ")
    # strings.replace(".", " ")
    # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼å¼•æ“
    listOfWords = re.split(r"\W", strings)
    # è¿”å›å°å†™å½¢å¼
    return [word.lower() for word in listOfWords if len(word) > 1]


# æµ‹è¯•testParse
def Test_testParse():
    stopLists = textParse(stopwords)
    print(stopLists)


# å…¨å±€å‚æ•°
stopwords_set = set(textParse(stopwords))


# äººç‰©ä¿¡æ¯
class person:
    def __init__(self, name, category, description):
        self.name = name
        self.category = category
        self.description = description
        self.wordList = []  # å»é™¤è¿‡æ»¤è¯çš„ä¸é‡å¤å•è¯åˆ—è¡¨

    def __str__(self):
        return "name:{}\ncategory:{}\ndescription:{}\nwordList:{}\n". \
            format(self.name, self.category, self.description, self.wordList)


# æ ¹æ®personçš„descriptionå»é™¤é‡å¤å•è¯å’Œè¿‡æ»¤è¯æ±‡
def filter_persons(p: person):
    p.wordList = sorted(set(textParse(p.description)) - stopwords_set)


# è¯»å–txtæ–‡ä»¶ï¼Œè¿”å›äººç‰©ä¿¡æ¯åˆ—è¡¨
def readTxt(path):
    persons = []
    with open(path, 'r', encoding='utf8') as f:
        file = f.read().splitlines()
        index = 0
        p = person('', '', '')
        for lines in file:
            if len(lines) > 0:  # æ­¤è¡Œæ•°æ®æœ‰æ•ˆ
                if index == 0:  # è¡¨ç¤ºè¿™æ˜¯äººç‰©çš„å§“å
                    p.name = lines
                    index += 1
                elif index == 1:  # äººç‰©åˆ†ç±»
                    p.category = lines
                    index += 1
                else:  # äººç‰©æè¿°
                    p.description += lines + ' '
                    index += 1
            else:  # é‡åˆ°ç©ºè¡Œ
                index = 0
                if len(p.name) > 0:  # personæœ‰æ•ˆ
                    persons.append(p)
                p = person('', '', '')  # æ¸…ç©º
        if len(p.name) > 0:
            persons.append(p)
        for p in persons:
            filter_persons(p)
        return persons


# æ ¹æ®é¢˜ç›®è¦æ±‚ï¼Œéœ€è¦å°†è¯»å…¥çš„æ–‡ä»¶åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
def split_persons(persons, N):
    return persons[:N], persons[N:]


# è¯»å–txtç„¶åå°†å…¶åˆ’åˆ†ä¸ºæ•°æ®é›†å’Œæµ‹è¯•é›†
def prework(path, N):
    persons = readTxt(path)
    return split_persons(persons, N)


# æµ‹è¯•readTxt
def Test_readTxt():
    path = "./bioCorpus.txt"
    persons = readTxt(path)
    for p in persons:
        print(p)


# å»ºç«‹ä¸€ä¸ªåŒ…å«åœ¨æ‰€æœ‰æ–‡æ¡£å‡ºç°çš„ä¸é‡å¤å•è¯åˆ—è¡¨
def createVocabList(persons: List[person]):
    vocabSet = set([])  # ä½¿ç”¨setå»é‡
    for p in persons:
        vocabSet = vocabSet | set(p.wordList)
    return sorted(list(vocabSet))  # è¿”å›listå½¢å¼


# --------------------------------Step1-------------------------------

# å°†è®­ç»ƒæ ·æœ¬ä¸­æ ‡ç­¾æŒ‰å­—å…¸åºæ’åºï¼Œç„¶åè®¡ç®—å…ˆéªŒæ¦‚ç‡FreqT (C) = OccT (C)/|T|
def categoryFreq(persons_train: List[person]):
    category = sorted([p.category for p in persons_train])
    # print("category: ", category)
    category_counter = Counter(category)
    # print("Counter: ", category_counter)
    # å»é‡
    category_list = list(set(category))
    # print("list: ", category_list)
    # è®¡ç®—æ¦‚ç‡,ä½¿ç”¨å­—å…¸ä¿å­˜
    category_freq = {}
    for category_name in category_list:
        category_freq[category_name] = category_counter[category_name] / len(category)
    # print("prob: ", category_prob)
    return category_freq


# æµ‹è¯•å‡½æ•°
def Test_categoryFreq():
    path = "./bioCorpus.txt"
    persons = readTxt(path)
    person_train, _ = split_persons(persons, 5)
    prob = categoryFreq(person_train)
    print(prob)


# åˆ›å»ºè¯å‘é‡çŸ©é˜µï¼Œæ¨ªè½´è¯æ±‡è¡¨ï¼Œçºµè½´åˆ†ç±»categoryï¼Œè®¡ç®—è®­ç»ƒé›†ä¸­æ¯ä¸ªè¯åœ¨è¿™ä¸ªåˆ†ç±»ä¸­å‡ºç°çš„æ¦‚ç‡
# å³è®¡ç®— FreqT (W|C)
def word2categoryFreq(persons_train: List[person]):
    # è·å–æ¨ªè½´
    vocabList = createVocabList(persons_train)
    # çºµè½´
    categoryOrigin = [p.category for p in persons_train]
    categoryList = sorted(list(set(categoryOrigin)))
    # ä½¿ç”¨äºŒç»´å­—å…¸ä¿å­˜ FreqT (W|C)ï¼Œåˆå§‹åŒ–ä¸º0
    word2category = {}
    for vocab in vocabList:
        word2category[vocab] = {}
        for c in categoryList:
            word2category[vocab][c] = 0

    categoryNum = Counter(categoryOrigin)
    # ä½¿ç”¨Counterè®¡ç®—æ¯ä¸ªå•è¯åœ¨æ¯ä¸ªåˆ†ç±»ä¸­å‡ºç°çš„æ¬¡æ•°
    categoryCounter = {}
    for c in categoryList:
        categoryCounter[c] = Counter()
    for p in persons_train:
        categoryCounter[p.category] += Counter(p.wordList)
    # è®¡ç®— FreqT (W|C)
    for vocab in vocabList:
        for c in categoryList:
            if categoryCounter[c].get(vocab) is not None:
                word2category[vocab][c] = categoryCounter[c][vocab] / categoryNum[c]
            else:
                word2category[vocab][c] = 0.0
    return vocabList, categoryList, word2category


def Test_word2categoryFreq():
    path = "./bioCorpus.txt"
    persons = readTxt(path)
    person_train, _ = split_persons(persons, 5)
    prob = word2categoryFreq(person_train)
    print(prob)


# --------------------------------Step2-------------------------------
# è®¡ç®—æ¦‚ç‡ For each classification C and word W, compute the probabilities using the Laplacian correction. Let  = 0.1.
# è®¡ç®—P(C),è¿”å›ä¸€ç»´å­—å…¸
def categoryProb(categoryFreq: dict):
    category_prob = {}
    for c, freq in categoryFreq.items():
        category_prob[c] = (freq + laplace) / (1 + len(categoryFreq) * laplace)
    return category_prob


# è®¡ç®—P(W|C)ï¼Œè¿”å›äºŒç»´å­—å…¸
def word2categoryProb(vocabList: List, categoryList: List, word2category: dict):
    word2category_prob = {}
    for vocab in vocabList:
        word2category_prob[vocab] = {}
        for c in categoryList:
            word2category_prob[vocab][c] = (word2category[vocab][c] + laplace) / (1 + 2 * laplace)
    return word2category_prob


# --------------------------------Step3-------------------------------
# è®¡ç®—è´Ÿå¯¹æ•° Compute negative log probabilities to avoid underflow
nlog = lambda x: -math.log(x, 2)  # è®¡ç®—ä»¥2ä¸ºåº•çš„å¯¹æ•°


def categoryProbLog(categoryProb: dict):
    category_log = {}
    for c, prob in categoryProb.items():
        category_log[c] = nlog(prob)
    return category_log


# è®¡ç®—P(W|C)ï¼Œè¿”å›äºŒç»´å­—å…¸
def word2categoryProbLog(vocabList: List, categoryList: List, word2category_prob: dict):
    word2category_log = {}
    for vocab in vocabList:
        word2category_log[vocab] = {}
        for c in categoryList:
            word2category_log[vocab][c] = nlog(word2category_prob[vocab][c])
    return word2category_log


def Test_Log():
    path = "./bioCorpus.txt"
    persons = readTxt(path)
    person_train, _ = split_persons(persons, 5)
    vocabList, categoryList, word2category = word2categoryFreq(person_train)
    word2category_prob = word2categoryProb(vocabList, categoryList, word2category)
    print("prob: ", word2category_prob)
    word2category_log = word2categoryProbLog(vocabList, categoryList, word2category_prob)
    print("log: ", word2category_log)


def trainNativeBayes(persons_train: List[person]):
    """
    :param persons_train:
    :return:
    """
    # è®¡ç®—L(C)
    category_freq = categoryFreq(persons_train)
    category_prob = categoryProb(category_freq)
    category_log = categoryProbLog(category_prob)

    # è®¡ç®—L(W/C)
    vocabList, categoryList, word2category = word2categoryFreq(persons_train)
    word2category_prob = word2categoryProb(vocabList, categoryList, word2category)
    word2category_log = word2categoryProbLog(vocabList, categoryList, word2category_prob)

    return vocabList, categoryList, category_log, word2category_log


# --------------------------------Step4-------------------------------
# Applying the classifier to the test data
# ä½¿ç”¨è®­ç»ƒçš„åˆ†ç±»å™¨åº”ç”¨äºæµ‹è¯•æ•°æ®é›†
# The prediction of the algorithm is the category C with the smallest value of L(C|B).
def classifyPerson(p: person, vocabList: List, categoryList: List, category_log: dict, word2category_log: dict):
    category_classify = {}
    p.wordList = set(p.wordList) & set(vocabList)  # åªä¿ç•™è®­ç»ƒé›†ä¸­çš„è¯æ±‡
    for c in categoryList:
        category_classify[c] = category_log[c]
        for vocab in p.wordList:
            category_classify[c] += word2category_log[vocab][c]
    # è®¡ç®—å„ä¸ªç±»åˆ«çš„æ¦‚ç‡
    m = min(list(category_classify.values()))  # åˆ†ç±»æœ€å°å€¼
    classify_prob = {}
    for c in categoryList:
        ci = category_classify[c]
        if ci - m < 7:
            classify_prob[c] = 2 ** (ci - m)
        else:
            classify_prob[c] = 0
    s = sum(classify_prob.values())
    for c in categoryList:
        classify_prob[c] = classify_prob[c] / s
    return classify_prob


def output(p: person, categoryList: List, classify_prob: dict):
    prediction = ""
    prob = 0
    for c in categoryList:
        if classify_prob[c] > prob:
            prob = classify_prob[c]
            prediction = c
    flag = "Right." if prediction == p.category else "Wrong."
    print("{}\t Prediction:{}\t {}".format(p.name, prediction, flag))
    probility = ""
    for c in categoryList:
        probility += "%s:%.2f   " % (c, classify_prob[c])
    print(probility)


def Test_classify():
    path = "./bioCorpus.txt"
    N = 10
    persons_train, persons_test = prework(path, N)
    vocabList, categoryList, category_log, word2category_log = trainNativeBayes(persons_train)
    for p in persons_test:
        classify_prob = classifyPerson(p, vocabList, categoryList, category_log, word2category_log)
        output(p, categoryList, classify_prob)


if __name__ == "__main__":
    Test_classify()
